{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c936a8",
   "metadata": {},
   "source": [
    "# Web Mining and Applied NLP (44-620)\n",
    "\n",
    "## Article and Comment Sentiment Analysis\n",
    "\n",
    "### Student Name: Kami Denny\n",
    "\n",
    "I’m fascinated by emotionally charged topics related to female health, particularly those that spark intense public discussion. This article, https://www.msn.com/en-us/news/world/real-reason-behind-birth-rate-decline/ar-AA1JMkgh?ocid=BingNewsSerp#comments, explores global birth rate decline and includes reader comments that offer strong and varied opinions. I’m eager to apply topic modeling and sentiment analysis to uncover how people—especially across gender lines—engage with this issue.\n",
    "\n",
    "- Comparing sentiment polarity between the article and its comment section\n",
    "\n",
    "- Exploring gender-based sentiment differences in reader responses\n",
    "\n",
    "- Identifying dominant themes using topic modeling and named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4d2a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "annotated-types         0.7.0\n",
      "asttokens               3.0.0\n",
      "beautifulsoup4          4.13.4\n",
      "blis                    1.3.0\n",
      "catalogue               2.0.10\n",
      "certifi                 2025.8.3\n",
      "charset-normalizer      3.4.2\n",
      "click                   8.2.1\n",
      "cloudpathlib            0.21.1\n",
      "colorama                0.4.6\n",
      "comm                    0.2.3\n",
      "confection              0.1.5\n",
      "contourpy               1.3.3\n",
      "cycler                  0.12.1\n",
      "cymem                   2.0.11\n",
      "debugpy                 1.8.15\n",
      "decorator               5.2.1\n",
      "en_core_web_sm          3.8.0\n",
      "executing               2.2.0\n",
      "fonttools               4.59.0\n",
      "html5lib                1.1\n",
      "idna                    3.10\n",
      "ipykernel               6.30.1\n",
      "ipython                 9.4.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.6\n",
      "joblib                  1.5.1\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.8.1\n",
      "kiwisolver              1.4.8\n",
      "langcodes               3.5.0\n",
      "language_data           1.3.0\n",
      "marisa-trie             1.2.1\n",
      "markdown-it-py          3.0.0\n",
      "MarkupSafe              3.0.2\n",
      "matplotlib              3.10.5\n",
      "matplotlib-inline       0.1.7\n",
      "mdurl                   0.1.2\n",
      "murmurhash              1.0.13\n",
      "nest-asyncio            1.6.0\n",
      "nltk                    3.9.1\n",
      "numpy                   2.3.2\n",
      "packaging               25.0\n",
      "parso                   0.8.4\n",
      "pillow                  11.3.0\n",
      "pip                     25.2\n",
      "platformdirs            4.3.8\n",
      "preshed                 3.0.10\n",
      "prompt_toolkit          3.0.51\n",
      "psutil                  7.0.0\n",
      "pure_eval               0.2.3\n",
      "pydantic                2.11.7\n",
      "pydantic_core           2.33.2\n",
      "Pygments                2.19.2\n",
      "pyparsing               3.2.3\n",
      "python-dateutil         2.9.0.post0\n",
      "pywin32                 311\n",
      "pyzmq                   27.0.1\n",
      "regex                   2025.7.34\n",
      "requests                2.32.4\n",
      "rich                    14.1.0\n",
      "setuptools              80.9.0\n",
      "shellingham             1.5.4\n",
      "six                     1.17.0\n",
      "smart_open              7.3.0.post1\n",
      "soupsieve               2.7\n",
      "spacy                   3.8.7\n",
      "spacy-legacy            3.0.12\n",
      "spacy-loggers           1.0.5\n",
      "spacytextblob           5.0.0\n",
      "srsly                   2.5.1\n",
      "stack-data              0.6.3\n",
      "textblob                0.19.0\n",
      "thinc                   8.3.6\n",
      "tornado                 6.5.1\n",
      "tqdm                    4.67.1\n",
      "traitlets               5.14.3\n",
      "typer                   0.16.0\n",
      "typing_extensions       4.14.1\n",
      "typing-inspection       0.4.1\n",
      "urllib3                 2.5.0\n",
      "wasabi                  1.1.3\n",
      "wcwidth                 0.2.13\n",
      "weasel                  0.4.1\n",
      "webencodings            0.5.1\n",
      "wheel                   0.45.1\n",
      "wrapt                   1.17.2\n",
      "All prereqs installed.\n"
     ]
    }
   ],
   "source": [
    "# This script installs necessary packages and checks their installation.\n",
    "\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import requests\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip list\n",
    "\n",
    "print('All prereqs installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4df6a",
   "metadata": {},
   "source": [
    "1. Find on the internet an article or blog post about a topic that interests you and you are able to get the text for using the technologies we have applied in the course. Get the html for the article and store it in a file (which you must submit with your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdebf786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status: 200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://speakingofwomenshealth.com/news/depo-provera-could-be-linked-to-a-heightened-risk-for-brain-tumors-in-some-women-a-new-study-warns\"\n",
    "\n",
    "# get the html for the article and store it in a pickle file\n",
    "response = requests.get(url)\n",
    "print(f\"Response status: {response.status_code}\")\n",
    "\n",
    "with open('article.pkl', 'wb') as f:\n",
    "    pickle.dump(response.text, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5217d38",
   "metadata": {},
   "source": [
    "2. Read in your article's html source from the file you created in question 1 and do sentiment analysis on the article/post's text (use .get_text()). Print the polarity score with an appropriate label. Additionally print the number of sentences in the original article (with an appropriate label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d589c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Polarity: 0.10918787878787878\n",
      "Article contains 14 sentences\n"
     ]
    }
   ],
   "source": [
    "# read in the article from the pickle file\n",
    "with open('article.pkl', 'rb') as f:\n",
    "    article_html = pickle.load(f)\n",
    "\n",
    "# use BeautifulSoup to parse the HTML and extract text\n",
    "soup = BeautifulSoup(article_html, 'html.parser')\n",
    "\n",
    "# Make sure spacytextblob is loaded\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "doc = nlp(soup.get_text())\n",
    "\n",
    "# exclude the first three sentences, and the last seven sentences. save as a variable\n",
    "filtered_sentences = list(doc.sents)[3:-7]\n",
    "\n",
    "# Calculate polarity of only the filtered sentences\n",
    "if filtered_sentences:\n",
    "    filtered_text = \" \".join([sent.text for sent in filtered_sentences])\n",
    "    filtered_doc = nlp(filtered_text)\n",
    "    article_polarity = filtered_doc._.blob.polarity\n",
    "else:\n",
    "    article_polarity = 0.0\n",
    "\n",
    "print(f\"Article Polarity: {article_polarity}\")\n",
    "\n",
    "print(f\"Article contains {len(filtered_sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50e227",
   "metadata": {},
   "source": [
    "1. Load the article text into a trained spaCy pipeline, and determine the 5 most frequent tokens (converted to lower case). Print the common tokens with an appropriate label. Additionally, print the tokens their frequencies (with appropriate labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c2c48e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common tokens:\n",
      "1. drugs, Frequency: 9\n",
      "2. risk, Frequency: 7\n",
      "3. women, Frequency: 5\n",
      "4. intracranial, Frequency: 5\n",
      "5. researchers, Frequency: 5\n"
     ]
    }
   ],
   "source": [
    "# Extract tokens from filtered sentences and find the most frequent ones\n",
    "filtered_tokens = []\n",
    "for sent in filtered_sentences:\n",
    "    for token in sent:\n",
    "        if token.pos_ in ['NOUN', 'PROPNOUN', 'ADJ', 'ADV'] and not token.is_stop and not token.is_punct:\n",
    "            filtered_tokens.append(token.text.lower())\n",
    "\n",
    "# Count token frequencies\n",
    "token_counts = Counter(filtered_tokens)\n",
    "\n",
    "print(\"Most common tokens:\")\n",
    "for i, (token, count) in enumerate(token_counts.most_common(5), 1):\n",
    "    print(f\"{i}. {token}, Frequency: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1f3dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article contains 14 sentences\n",
      "Sentence 1: The contraceptive injection Depo-Provera and two drugs used for menopause relief could be linked to a heightened risk for brain tumors in some women, a new study warns.\n",
      "Sentence 2: Depo-Provera (medroxyprogesterone acetate) increased the risk of intracranial meningioma 5.6-fold if used for longer than a year, researchers report in the BMJ.“In countries for which the use of medroxyprogesterone acetate for birth control is frequent [74 million users worldwide], the number of attributable meningiomas may be potentially high,” concluded the research team led by Noémie Roland, a general practitioner and epidemiologist with French National Health Insurance in Saint-Denis, France.\n",
      "Sentence 3: Further, the menopausal hormone therapy drugs medrogestone and promegestone increased the risk of intracranial meningiomas by 4.1-fold and 2.7-fold, respectively, results show.\n",
      "Sentence 4: Intracranial meningiomas are mostly non-cancerous tumors that grow in the layers of tissue that cover the brain and spinal cord, researchers said.\n",
      "Sentence 5: Meningiomas account for 40% of cancers in the central nervous system.\n",
      "Sentence 6: The three drugs all contained progestogens, which are similar to the natural hormone progesterone.\n",
      "Sentence 7: This class of drugs also are used to treat conditions like endometriosis and ovarian cysts.\n",
      "Sentence 8: For the study, researchers analyzed French health system data for more than 18,000 women who underwent surgery for intracranial meningioma between 2009 and 2018.Each case was matched to five other women who didn’t have an intracranial meningioma.\n",
      "Sentence 9: The research team tracked women’s use of the progestogen drugs progesterone, hydroxyprogesterone, dydrogesterone, medrogestone, medroxyprogesterone acetate, promegestone, dienogest and levonorgestrel.\n",
      "Sentence 10: Prolonged use was defined as a year or more, as there appeared to be no risk posed by using the drugs for less than one year, researchers said.\n",
      "Sentence 11: None of the other drugs showed an increased risk for meningioma, including levonorgestrel, a hormone used in IUD contraceptive devices and in emergency contraceptives like Plan B.Researchers warned that because this was an observational study, it couldn’t draw a direct cause-and-effect link between the drugs and brain tumors.\n",
      "Sentence 12: More research is needed to understand why these specific drugs might increase tumor risk in some women.\n",
      "Sentence 13: “Future studies should further clarify the association between the duration of use and risk for the progestogens studied,” the team said.\n",
      "Sentence 14: Progesterone receptors are present in more than 60% of meningiomas, which could provide one potential explanation, researchers said.\n",
      "\n",
      "Sentence Polarity:\n",
      "Sentence 1 Polarity: 0.13636363636363635\n",
      "Sentence 2 Polarity: 0.07750000000000001\n",
      "Sentence 3 Polarity: 0.0\n",
      "Sentence 4 Polarity: 0.5\n",
      "Sentence 5 Polarity: 0.0\n",
      "Sentence 6 Polarity: 0.05\n",
      "Sentence 7 Polarity: 0.0\n",
      "Sentence 8 Polarity: 0.125\n",
      "Sentence 9 Polarity: 0.0\n",
      "Sentence 10 Polarity: 0.16666666666666669\n",
      "Sentence 11 Polarity: -0.012499999999999997\n",
      "Sentence 12 Polarity: 0.25\n",
      "Sentence 13 Polarity: 0.0\n",
      "Sentence 14 Polarity: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# read in the article from the pickle file\n",
    "with open('article.pkl', 'rb') as f:\n",
    "    article_html = pickle.load(f)\n",
    "\n",
    "# use BeautifulSoup to parse the HTML and extract text\n",
    "soup = BeautifulSoup(article_html, 'html.parser')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(soup.get_text())\n",
    "\n",
    "# exclude the first three sentences, and the last five sentences. save as a variable\n",
    "filtered_sentences = list(doc.sents)[3:-7]\n",
    "\n",
    "# Print the filtered sentences\n",
    "print(f\"Article contains {len(filtered_sentences)} sentences\")\n",
    "for i, sent in enumerate(filtered_sentences, start=1):\n",
    "    print(f\"Sentence {i}: {sent.text.strip()}\")\n",
    "\n",
    "# print the polarity of the filtered sentences\n",
    "print(\"\\nSentence Polarity:\")\n",
    "for i, sent in enumerate(filtered_sentences, start=1):\n",
    "    print(f\"Sentence {i} Polarity: {sent._.blob.polarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
